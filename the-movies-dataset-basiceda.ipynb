{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 0. Data Load"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from subprocess import check_output\nimport subprocess\n\nfiles = check_output(['ls','../input/the-movies-dataset']).decode('utf8')\n# files\nfor file in files.split(\"\\n\"):\n#     print(file)\n    path='../input/the-movies-dataset/'+ file\n    popenobj=subprocess.Popen(['wc', '-l', path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n#     print(popenobj)\n    result,error= popenobj.communicate()\n    print(\"The file :\",file,\"has :\",result.strip().split()[0],\"rows\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_pd = pd.read_csv('/kaggle/input/the-movies-dataset/ratings.csv')\nlinks_small_pd = pd.read_csv('/kaggle/input/the-movies-dataset/links_small.csv')\ncredits_pd = pd.read_csv('/kaggle/input/the-movies-dataset/credits.csv')\nkeywords_pd = pd.read_csv('/kaggle/input/the-movies-dataset/keywords.csv')\nmovies_metadata_pd = pd.read_csv('/kaggle/input/the-movies-dataset/movies_metadata.csv')\nratings_small_pd = pd.read_csv('/kaggle/input/the-movies-dataset/ratings_small.csv')\nlinks_pd = pd.read_csv('/kaggle/input/the-movies-dataset/links.csv')\n\nprint('*** df 생성 완료 ***')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Memory Optimization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_dtypes(file_path):\n    \n    tmp = pd.read_csv(file_path, nrows=0)\n    \n    col_dtypes = {}\n    for col in tmp.columns:\n        df = pd.read_csv(file_path, usecols=[col])\n        dtype = df[col].dtype\n        \n        if dtype == 'int' or dtype == 'float':\n            c_min = df[col].min()\n            c_max = df[col].max()\n        elif dtype == 'object':\n            n_unique = df[col].nunique()\n            threshold = n_unique / df.shape[0]\n            \n        if dtype == 'int':\n            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                col_dtype = 'int8'\n            elif c_min > np.iinfo(np.uint8).min and c_max < np.iinfo(np.uint8).max:\n                col_dtype = 'uint8'\n            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                col_dtype = 'int16'\n            elif c_min > np.iinfo(np.uint16).min and c_max < np.iinfo(np.uint16).max:\n                col_dtype = 'uint16'\n            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                col_dtype = 'int32'\n            elif c_min > np.iinfo(np.uint32).min and c_max < np.iinfo(np.uint32).max:\n                col_dtype = 'uint32'\n            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                col_dtype = 'int64'\n            elif c_min > np.iinfo(np.uint64).min and c_max < np.iinfo(np.uint64).max:\n                col_dtype = 'uint64'\n        elif dtype == 'float':\n            if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                col_dtype = 'float32'\n            else :\n                col_dtype = 'float64'\n        elif dtype == 'object':\n            if threshold > 0.7:\n                col_dtype = 'object'\n            else :\n                col_dtype = 'category'\n                \n        col_dtypes[col] = col_dtype\n    \n    return col_dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_types=check_dtypes('/kaggle/input/the-movies-dataset/movies_metadata.csv')\nprint(\"***movies_metadata***\")\nmemory = movies_metadata_pd.memory_usage(index=True).sum()\nprint(\"Original dataset uses \", memory/ 1024**2,\" MB\")\nmovies_metadata_pd = movies_metadata_pd.astype(data_types)\nnew_memory = movies_metadata_pd.memory_usage(index=True).sum()\nprint(\"dataset uses \",new_memory/ 1024**2,\" MB after changes\")\nprint(\"memory saved =\",(memory-new_memory)/ 1024**2,\" MB\")\nprint(\"==========================================================\")\n\ndata_types=check_dtypes('/kaggle/input/the-movies-dataset/credits.csv')\nprint(\"***credits***\")\nmemory = credits_pd.memory_usage(index=True).sum()\nprint(\"Original dataset uses \", memory/ 1024**2,\" MB\")\ncredits_pd = credits_pd.astype(data_types)\nnew_memory = credits_pd.memory_usage(index=True).sum()\nprint(\"dataset uses \",new_memory/ 1024**2,\" MB after changes\")\nprint(\"memory saved =\",(memory-new_memory)/ 1024**2,\" MB\")\nprint(\"==========================================================\")\n\ndata_types=check_dtypes('/kaggle/input/the-movies-dataset/keywords.csv')\nprint(\"***keywords***\")\nmemory = keywords_pd.memory_usage(index=True).sum()\nprint(\"Original dataset uses \", memory/ 1024**2,\" MB\")\nkeywords_pd = keywords_pd.astype(data_types)\nnew_memory = keywords_pd.memory_usage(index=True).sum()\nprint(\"dataset uses \",new_memory/ 1024**2,\" MB after changes\")\nprint(\"memory saved =\",(memory-new_memory)/ 1024**2,\" MB\")\nprint(\"==========================================================\")\n\ndata_types=check_dtypes('/kaggle/input/the-movies-dataset/links.csv')\nprint(\"***links***\")\nmemory = links_pd.memory_usage(index=True).sum()\nprint(\"Original dataset uses \", memory/ 1024**2,\" MB\")\nlinks_pd = links_pd.astype(data_types)\nnew_memory = links_pd.memory_usage(index=True).sum()\nprint(\"dataset uses \",new_memory/ 1024**2,\" MB after changes\")\nprint(\"memory saved =\",(memory-new_memory)/ 1024**2,\" MB\")\nprint(\"==========================================================\")\n\ndata_types=check_dtypes('/kaggle/input/the-movies-dataset/ratings.csv')\nprint(\"***ratings***\")\nmemory = ratings_pd.memory_usage(index=True).sum()\nprint(\"Original dataset uses \", memory/ 1024**2,\" MB\")\nratings_pd = ratings_pd.astype(data_types)\nnew_memory = ratings_pd.memory_usage(index=True).sum()\nprint(\"dataset uses \",new_memory/ 1024**2,\" MB after changes\")\nprint(\"memory saved =\",(memory-new_memory)/ 1024**2,\" MB\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Basic EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns \nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 0) Check Each Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"credits_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keywords_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keywords_pd.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 범주가 무수히 많은 경우엔, 메모리 활용에 있어 category 타입이 object 보다 비효율적인 점 확인\n# object 타입으로 재변경\nkeywords_pd['keywords'] = keywords_pd['keywords'].astype('object')\nprint((keywords_pd.memory_usage(index=True).sum())/ 1024**2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_metadata_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_metadata_pd.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"links_pd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1) ratings_pd"},{"metadata":{"trusted":true},"cell_type":"code","source":"ratings_pd.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# delete 'timestamp' column\ndel ratings_pd[\"timestamp\"]\nratings_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check 'ratings' column distribution\nnumberByRatings = ratings_pd.groupby(by=['rating']).count()\ndel numberByRatings['movieId']\nnumberByRatings.columns = ['count']\nget_ratio = lambda x :round(x/ratings_pd.shape[0]*100,2)\nnumberByRatings['ratio'] = numberByRatings.apply(get_ratio)\nnumberByRatings","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches(12, 7)\nax = sns.countplot(x=\"rating\", data=ratings_pd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# usetid\nratings_pd['userId'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = ratings_pd.groupby(by=['userId']).count()\ndel df['movieId']\ndf.columns = ['count']\ndf.sort_values(by='count', ascending=False).head(20)\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# movieid\ndf = ratings_pd.groupby(by=['movieId']).count()\ndel df['userId']\ndf.columns = ['count']\nprint(df.sort_values(by='count', ascending=False).head(10))\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2) credits_pd"},{"metadata":{"trusted":true},"cell_type":"code","source":"credits_pd.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(credits_pd.cast)\ndf.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.cast[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(credits_pd.crew)\ndf.drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.crew[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3) keywords_pd"},{"metadata":{"trusted":true},"cell_type":"code","source":"keywords_pd.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(keywords_pd.keywords)\ndf = df.drop_duplicates()\nprint(\"Drop Duplicates : \",(keywords_pd.shape[0]-df.shape[0]), \"개 /\",round((keywords_pd.shape[0]-df.shape[0])/keywords_pd.shape[0]*100,2),\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.keywords[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\nkeywords_group = []\n\nfor i in df.index:\n    value = df._get_value(i,'keywords')\n#     print(value)\n#     print(type(value))\n    line = re.findall('{(.+?)}', value)\n#     print(line)\n    for l in line:\n#         l.replace('\\\\','-')\n        if l not in keywords_group:\n            keywords_group.append(l)\nlen(keywords_group)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keywords_group","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keys = []\nvalues = []\nfor k in keywords_group:\n    keys.append(k.split(',')[0][6:])\n    values.append(k.split(',')[1][10:-1])\n# print(len(keys))\n# print(len(values))\nkeywords_dict = dict(zip(keys,values))\nkeywords_dict","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 4) movies_metadata_pd"},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_metadata_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_metadata_pd.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"movies_metadata_pd[['popularity','poster_path','production_companies','production_countries']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata = movies_metadata_pd.drop(['homepage','imdb_id','poster_path','runtime','original_title','video'], axis=1)\nmetadata","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(metadata[metadata['adult'] == 'True']))\nmetadata[metadata['adult'] == 'True']['title']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata.adult.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata[metadata['adult'] != 'False']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metadata.belongs_to_collection.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# budget 값이 0인 데이터 수 및 비율\nprint(len(metadata[metadata['budget'] == '0']), \"건\")\nprint(round(len(metadata[metadata['budget'] == '0'])/metadata.shape[0]*100),\"%\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nfrom ast import literal_eval\n\n# metadata['production_countries'] = metadata['production_countries'].astype('object')\nmetadata['production_countries'][0]\nnull_index = metadata[metadata['production_countries'].isnull()].index\nmovies_metadata_pd.loc[null_index][:] # 원본데이터에서도 의미없는 데이터인점 확인\n# metadata.drop(null_index)\nresult = metadata.production_countries.to_json(orient=\"index\")\n# print(result)\nresult = json.loads(result)\n# print(json.dumps(result, indent=4))\n# type(result) #dict type\n# for i in result.values():\n#     print(i)\n# type(result['0'])\nresult_dict = literal_eval(result.values())\nresult_dict['name']\n# for i in metadata.production_countries:\n#     print(i['name'])\n# metadata['production_countries'].apply(lambda x:[i['name'] for i in x])\n# metadata['production_countries'] = metadata['production_countries'].apply(lambda x:[i['name'] for i in x])\n# metadata['production_countries']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python --version","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}